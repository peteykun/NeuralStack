{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Embedding size\n",
    "m = 64\n",
    "\n",
    "# Hidden size\n",
    "hidden_size = 128\n",
    "\n",
    "# Batch_size\n",
    "batch_size_config = 2\n",
    "\n",
    "# Stack initialized?\n",
    "init = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.2)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = None\n",
    "V = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pop operation helpers\n",
    "def check(stack, strengths, remaining, read, idx):\n",
    "    # Bottom of stack\n",
    "    return idx >= 0 #tf.logical_and(idx >= 1, remaining != 0)\n",
    "\n",
    "def update(stack, strengths, remaining, read, idx):\n",
    "    # Amount we can use at this step\n",
    "    this_qty = tf.minimum(remaining, strengths[:,:,idx:idx+1])\n",
    "\n",
    "    # Update read value\n",
    "    old_read = read\n",
    "    read = tf.reshape(read + tf.reshape(this_qty * V[:,:,idx:idx+1], tf.shape(read)), tf.shape(read))  # for shape constraints\n",
    "\n",
    "    # Update remaining strength\n",
    "    remaining = tf.reshape(remaining - this_qty, tf.shape(remaining))\n",
    "\n",
    "    # Update strengths\n",
    "    before = strengths[:,:,:idx]\n",
    "    this   = tf.reshape(tf.sub(strengths[:,:,idx:idx+1], this_qty), (-1, 1, 1))\n",
    "    after  = strengths[:,:,idx+1:]\n",
    "\n",
    "    strengths = tf.reshape(tf.concat(2, [before, this, after]), tf.shape(strengths), name=\"strength_cat\")\n",
    "\n",
    "    # Update index\n",
    "    idx = idx - 1\n",
    "\n",
    "    return (stack, strengths, remaining, read, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def symbolic_stack_update(d, u, v):\n",
    "    '''\n",
    "    Performs an update to the neural stack.\n",
    "    \n",
    "    Args:\n",
    "      d: Push probability.\n",
    "      u: Pop probability.\n",
    "      v: Push value.\n",
    "    \n",
    "    Returns:\n",
    "      r: The value read from the stack.\n",
    "    '''\n",
    "    global s, V, m, init\n",
    "    \n",
    "    # Infer batch size\n",
    "    batch_size = tf.shape(d)[0]\n",
    "    \n",
    "    if init:\n",
    "        # Infer stack size\n",
    "        stack_size = tf.shape(V)[2]\n",
    "        \n",
    "        # Perform initializations\n",
    "        read0     = tf.zeros((batch_size, m))      # Read value\n",
    "        idx0      = stack_size - 1                  # Index into the stack\n",
    "        \n",
    "        initialization = (V, s, u, read0, idx0)\n",
    "        pop_operation = tf.while_loop(check, update, initialization)\n",
    "        \n",
    "        # Update strengths and perform read\n",
    "        s = pop_operation[1]\n",
    "        r = pop_operation[3]\n",
    "        \n",
    "        # Perform push\n",
    "        V = tf.concat(2, [V, v])\n",
    "        s = tf.concat(2, [s, d])\n",
    "        \n",
    "    else:\n",
    "        r = tf.zeros((batch_size, m), dtype=np.float32)\n",
    "        init = True\n",
    "        pop_operation = None\n",
    "        \n",
    "        # Initialize stack\n",
    "        V = v\n",
    "        s = d\n",
    "    \n",
    "    return r, pop_operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reads = []\n",
    "pops  = []\n",
    "num_ops = 5\n",
    "\n",
    "d_ = [tf.placeholder(tf.float32, shape=(batch_size_config, 1, 1), name=\"d_%i\" % t) for t in range(num_ops)]\n",
    "u_ = [tf.placeholder(tf.float32, shape=(batch_size_config, 1, 1), name=\"u_%i\" % t) for t in range(num_ops)]\n",
    "v_ = [tf.placeholder(tf.float32, shape=(batch_size_config, m, 1), name=\"v_%i\" % t) for t in range(num_ops)]\n",
    "\n",
    "for t in range(num_ops):\n",
    "    read_t, pop_t = symbolic_stack_update(d_[t], u_[t], v_[t])\n",
    "    reads.append(read_t)\n",
    "    pops.append(pop_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feed_dict = {d_[t]: np.reshape([1.0] * 2, (2, 1, 1)).astype(np.float) for t in range(num_ops)}\n",
    "feed_dict.update({u_[0]: np.reshape([0.0] * 2, (2, 1, 1)).astype(np.float)})\n",
    "feed_dict.update({u_[t]: np.reshape([1.0] * 2, (2, 1, 1)).astype(np.float) for t in range(1, num_ops)})\n",
    "feed_dict.update({v_[t]: np.reshape(np.eye(m)[t:t+2], (2, 64, 1)).astype(np.float) for t in range(num_ops)})\n",
    "\n",
    "reads_t = sess.run(reads, feed_dict)\n",
    "\n",
    "for read_t in reads_t:\n",
    "    print read_t[0].astype(np.int32)\n",
    "    print read_t[1].astype(np.int32)\n",
    "    print ''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
